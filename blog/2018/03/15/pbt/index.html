<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  
  
  <title>On DeepMind&#39;s Population-Based Training</title>
  <meta name="description" content="DeepMind has recently released a paper about population-based training of neural nets. The proposition is a simple asynchronous optimization algorithm, which jointly optimizes a population of models and their hyperparameters. In this post, I aim to demonstrate a simple implementation of the algorithm by reproducing the paper’s Figure 2. The objective is to maximize the function def q(theta): return 1.2 - np.sum(np.array(theta)**2) Think of the above function as the validation set performance whose closed-form expression is unknown. However, we can still query its value $($ evaluate $)$ at specific $\theta$. While our goal is to maximize it and achieve a model with good generalization capabilities, we optimize our neural model $($ tune its parameters $)$ with respect to the training set performance. That is, our model is optimized w.r.t. to a surrogate objective $\hat{Q}$ function rather than the objective function we are after. In an ideal setup, one would like $\hat{Q}=Q$ $($ or at least optimizing $\hat{Q}$ should correspond to optimizing $Q$ as well$)$, but this is not the case in general. The quality of this approximation $($or coupled optimization $)$ is often dependent on the model at hand and how we are training it: the hyperparameters. In other words, when we optimize $\hat{Q}$ w.r.t. $\theta$, we are doing so given $($ conditioned on $)$ a set of hyperparameters, $\hat{Q}(\theta\mid h)$. In the considered toy example, let the mpirical loss / training set performance by parameterized by $h$ as follows. def q_hat(theta, h): # this is used by `step` function to perform # gradient updates return 1.2 - np.sum(np.dot(np.array(h), np.array(theta)**2)) The task now boils down to using $\hat{Q}$ to tune $\theta$ while searching for $h$ to make the tuning process as efficient as possible in $($ indirectly $)$ optimizing $Q$. PBT is one solution to do so. Here is the pesudocode, and below is an implementation of the same. Let’s start with modeling the population members: class Member(object): def __init__(self, theta=[0., 0.], h=[0., 0.], _id=1, _eta=0.01, _sigma=1e-1): self.theta = theta self.h = h self.id = _id self.num_steps = 0 self.p = q(self.theta) self._eta = _eta self._sigma = _sigma ## for visualization self.trace = [] self.ps = [self.p] def eval(self): self.p = q(self.theta) def ready(self): return self.num_steps &amp;gt; 10 def step(self): for i in range(2): self.theta[i] += self._eta * (-2. * self.h[i] * self.theta[i]) self.num_steps += 1 def explore(self): for i in range(2): self.h[i] = np.clip(self.h[i] + self._sigma * np.random.randn(), 0, 1) def exploit(self, other): if self.p &amp;lt;= other.p: self.theta = list(other.theta) self.p = other.p self.num_steps = 0 return True else: return False def log(self): self.trace.append(list(self.theta)) self.ps.append(self.p) def __str__(self): return &#39;theta:&#39; + &#39;%.2f&#39; % self.theta[0] + &#39;,%.2f&#39; % self.theta[1] + \ &#39;| h:&#39; + &#39;%.2f&#39; % self.h[0] + &#39;,%.2f&#39; % self.h[1] + &#39;| id&#39; + str(self.id) + \ &#39;| p:&#39; + &#39;%.2f&#39; % self.p + &#39;| steps:&#39; + str(self.num_steps) Here’s PBT implementation. I’ve put flags to show PBT in explore, exploit, grid search modes. def pbt(grid=False, explore_only=False, exploit_only=False): # a check to ensure only one mode is selected for PBT assert grid + exploit_only + explore_only &amp;lt;= 1, &quot;at most one flag can be set for PBT modes&quot; # init population population = [ Member(theta=[0.9, 0.9], h=[0,1], _id=0), Member(theta=[0.9, 0.9], h=[1,0], _id=1) ] member_ids = np.arange(len(population)) # begin training for _ in range(75): np.random.shuffle(member_ids) for mem_id in member_ids: member = population[mem_id] member.step() member.eval() if member.ready() and not grid: if explore_only: member.explore() else: member.exploit(population[(mem_id + 1) % 2]) if not exploit_only: member.explore() member.eval() member.log() traces = [population[i].trace for i in range(len(population))] ps = [population[i].ps for i in range(len(population))] return traces, ps Let’s plot the four modes f, axes = plt.subplots(2, 4)#, sharex=True) traces, ps = pbt(grid=True) plot_traces(axes[0,0], traces, title=&#39;Grid Search&#39;) plot_curves(axes[0,2], ps, title=&#39;Grid Serach&#39;) traces, ps = pbt(exploit_only=True) plot_traces(axes[0,1], traces, title=&#39;Exploit Only&#39;) plot_curves(axes[0,3], ps, title=&#39;Exploit Only&#39;) traces, ps = pbt(explore_only=True) plot_traces(axes[1,0], traces, title=&#39;Explore Only&#39;) plot_curves(axes[1,2], ps, title=&#39;Explore Only&#39;) traces, ps = pbt() plot_traces(axes[1,1], traces, title=&#39;PBT&#39;) plot_curves(axes[1,3], ps, title=&#39;PBT&#39;) plt.tight_layout() plt.show() which results in the following:">
  

  <link rel="stylesheet" href="/blog/assets/main.css">
  <link rel="canonical" href="http://ash-aldujaili.github.io/blog/2018/03/15/pbt/">
  
  
  <link rel="alternate" type="application/rss+xml" title="Hunting Optima" href="http://ash-aldujaili.github.io/blog/feed.xml">

  

  
  <meta name="twitter:card" content="summary">
  
  <meta name="twitter:title" content="On DeepMind&#39;s Population-Based Training">
  <meta name="twitter:description" content="DeepMind has recently released a paper about population-based training of neural nets. The proposition is a simple asynchronous optimization algorithm, which jointly optimizes a population of model...">
  
  

  <script type="text/javascript">
  WebFontConfig = {
    google: { families: [ 'Bitter:400,700,400italic:latin' ] }
  };
  (function() {
    var wf = document.createElement('script');
    wf.src = ('https:' == document.location.protocol ? 'https' : 'http') +
      '://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
    wf.type = 'text/javascript';
    wf.async = 'true';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(wf, s);
  })();
</script>

  
  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-68645681-6', 'auto');
    ga('send', 'pageview');

  </script>


</head>

  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
      inlineMath: [ ['$','$'] ],
      displayMath: [ ['$$','$$'] ],
      processEscapes: false,
    }
  });
</script>
<script type="text/javascript"
        src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/blog/">Hunting Optima</a>

    <nav class="site-nav">
      
        
        <a class="page-link" href="http://ash-aldujaili.github.io/">Home</a>
      
        
        <a class="page-link" href="/blog/about/">About my blog</a>
      
        
        <a class="page-link" href="/blog/archives/">Archives</a>
      
        
        <a class="page-link" href="https://github.com/ash-aldujaili">GitHub</a>
      
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    
      <h1 class="post-title" itemprop="name headline">On DeepMind&#39;s Population-Based Training</h1>
                                       

    <p class="post-meta"><time datetime="2018-03-15T00:00:00-08:00" itemprop="datePublished">Mar 15, 2018</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>DeepMind has recently released a <a href="https://arxiv.org/abs/1711.09846">paper</a> about population-based training of neural nets. The proposition is a simple asynchronous optimization algorithm, which jointly optimizes a population of models and their hyperparameters. In this post, I aim to demonstrate a simple implementation of the algorithm by reproducing the paper’s Figure 2.</p>

<p align="center">
  <img src="http://ash-aldujaili.github.io/blog/assets/pbt/pbt-paper-demo.png" width="750" />
<br /><br />
</p>

<p>The objective is to maximize the function</p>

<script type="math/tex; mode=display">Q(\theta) = 1.2 - (\theta^2_0 + \theta^2_1)</script>

<div class="highlighter-rouge"><pre class="highlight"><code>def q(theta):
    return 1.2 - np.sum(np.array(theta)**2)
</code></pre>
</div>

<p>Think of the above function as the validation set performance whose closed-form expression is unknown. However, we can still query its value $($ evaluate $)$ at specific $\theta$. While our goal is to maximize it and achieve a model with good generalization capabilities, we optimize our neural model $($ tune its parameters $)$ with respect to the training set performance. That is, our model is optimized w.r.t. to a surrogate objective $\hat{Q}$ function rather than the objective function we are after.</p>

<p>In an ideal setup, one would like $\hat{Q}=Q$ $($ or at least optimizing $\hat{Q}$ should correspond to optimizing $Q$ as well$)$, but this is not the case in general. The quality of this approximation $($or coupled optimization $)$  is often dependent on the model at hand and how we are training it: the hyperparameters. In other words, when we optimize $\hat{Q}$ w.r.t. $\theta$, we are doing so given $($ conditioned on $)$ a set of hyperparameters, $\hat{Q}(\theta\mid h)$.</p>

<p>In the considered toy example, let the mpirical loss / training set performance by parameterized by $h$ as follows.
<script type="math/tex">\hat{Q}(\theta|h) = 1.2 - (h_0\theta^2_0 + h_1\theta^2_1)</script></p>

<div class="highlighter-rouge"><pre class="highlight"><code>def q_hat(theta, h):
    # this is used by `step` function to perform
    # gradient updates 
    return 1.2 - np.sum(np.dot(np.array(h), np.array(theta)**2))
</code></pre>
</div>

<p>The task now boils down to using $\hat{Q}$ to tune $\theta$ while searching for $h$ to make the tuning process as efficient as possible in $($ indirectly $)$ optimizing $Q$. PBT is one solution to do so. Here is the pesudocode, and below is an implementation of the same.</p>

<p align="center">
  <img src="http://ash-aldujaili.github.io/blog/assets/pbt/pbt-alg.png" width="750" />
<br /><br />
</p>

<p>Let’s start with modeling the population members:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>class Member(object):
    def __init__(self, theta=[0., 0.], h=[0., 0.], _id=1, _eta=0.01, _sigma=1e-1):
        self.theta = theta
        self.h = h
        self.id = _id
        self.num_steps = 0
        self.p = q(self.theta)
        self._eta = _eta
        self._sigma = _sigma
        ## for visualization
        self.trace = []
        self.ps = [self.p]

    def eval(self):
        self.p = q(self.theta)

    def ready(self):
        return self.num_steps &gt; 10

    def step(self):
        for i in range(2):
            self.theta[i] +=  self._eta * (-2. * self.h[i] * self.theta[i])
        self.num_steps += 1

    def explore(self):
        for i in range(2):
            self.h[i] = np.clip(self.h[i] + self._sigma * np.random.randn(), 0, 1)

    def exploit(self, other):
        if self.p &lt;= other.p:
            self.theta = list(other.theta)
            self.p = other.p
            self.num_steps = 0
            return True
        else:
            return False

    def log(self):
        self.trace.append(list(self.theta))
        self.ps.append(self.p)

    def __str__(self):
        return 'theta:' + '%.2f' % self.theta[0] + ',%.2f' % self.theta[1] + \
               '| h:' + '%.2f' % self.h[0] + ',%.2f' % self.h[1] + '| id' + str(self.id) + \
               '| p:' + '%.2f' % self.p + '| steps:' + str(self.num_steps)
</code></pre>
</div>

<p>Here’s PBT implementation. I’ve put flags to show PBT in explore, exploit, grid search modes.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>def pbt(grid=False, explore_only=False, exploit_only=False):
    # a check to ensure only one mode is selected for PBT
    assert grid + exploit_only + explore_only &lt;= 1, "at most one flag can be set for PBT modes"
    # init population
    population = [
        Member(theta=[0.9, 0.9], h=[0,1], _id=0),
        Member(theta=[0.9, 0.9], h=[1,0], _id=1)
        ]
    member_ids = np.arange(len(population))
    # begin training
    for _ in range(75):
        np.random.shuffle(member_ids)
        for mem_id in member_ids:
            member = population[mem_id]
            member.step()
            member.eval()
            if member.ready() and not grid:
                if explore_only:
                    member.explore()
                else:
                    member.exploit(population[(mem_id + 1) % 2])
                    if not exploit_only:
                        member.explore()
                    member.eval()
            member.log()

    traces = [population[i].trace for i in range(len(population))]
    ps = [population[i].ps for i in range(len(population))]
    return traces, ps
</code></pre>
</div>

<p>Let’s plot the four modes</p>

<div class="highlighter-rouge"><pre class="highlight"><code>f, axes = plt.subplots(2, 4)#, sharex=True)

traces, ps = pbt(grid=True)
plot_traces(axes[0,0], traces, title='Grid Search')
plot_curves(axes[0,2], ps, title='Grid Serach')

traces, ps = pbt(exploit_only=True)
plot_traces(axes[0,1], traces, title='Exploit Only')
plot_curves(axes[0,3], ps, title='Exploit Only')

traces, ps = pbt(explore_only=True)
plot_traces(axes[1,0], traces, title='Explore Only')
plot_curves(axes[1,2], ps, title='Explore Only')

traces, ps = pbt()
plot_traces(axes[1,1], traces, title='PBT')
plot_curves(axes[1,3], ps, title='PBT')

plt.tight_layout()
plt.show()
</code></pre>
</div>

<p>which results in the following:</p>

<p align="center">
  <img src="http://ash-aldujaili.github.io/blog/assets/pbt/pbt-demo.png" width="850" />
<br /><br />
</p>


  </div>

  
    <div id="disqus_thread"></div>
    <script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
  
    var disqus_config = function () {
    this.page.url = "http://ash-aldujaili.github.io/blog/2018/03/15/pbt/"; //'http://ash-aldujaili.github.io/blog/2017/06/06/mse-ego-dace/';  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = "/2018/03/15/pbt"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };

    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://ash-aldujaili.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

   

</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <p>
      

&copy; Abdullah Al-Dujaili - Powered by <a href="https://jekyllrb.com">Jekyll</a> &amp; <a href="https://github.com/yous/whiteglass">whiteglass</a> - Subscribe via <a href="http://ash-aldujaili.github.io/blog/feed.xml">RSS</a>

    </p>

  </div>

</footer>


    
  </body>

</html>
